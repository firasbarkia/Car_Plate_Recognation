{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Car Detection Model Training with YOLOv11\n",
        "\n",
        "This notebook trains a YOLOv11 model to detect cars in images using the Self Driving Car dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install ultralytics streamlit pillow opencv-python -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directories created successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Define paths\n",
        "dataset_root = Path(\"Self Driving Car.v3-fixed-small.yolov11\")\n",
        "export_images = dataset_root / \"export\" / \"images\"\n",
        "export_labels = dataset_root / \"export\" / \"labels\"\n",
        "\n",
        "# Create train/val/test directories\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    (dataset_root / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "    (dataset_root / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Directories created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Split Dataset into Train/Validation/Test Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 29800\n",
            "Train: 20860, Val: 5960, Test: 2980\n"
          ]
        }
      ],
      "source": [
        "# Get all image files\n",
        "image_files = list(export_images.glob(\"*.jpg\"))\n",
        "print(f\"Total images: {len(image_files)}\")\n",
        "\n",
        "# Shuffle and split: 70% train, 20% val, 10% test\n",
        "random.shuffle(image_files)\n",
        "train_size = int(0.7 * len(image_files))\n",
        "val_size = int(0.2 * len(image_files))\n",
        "\n",
        "train_files = image_files[:train_size]\n",
        "val_files = image_files[train_size:train_size + val_size]\n",
        "test_files = image_files[train_size + val_size:]\n",
        "\n",
        "print(f\"Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying training files...\n",
            "Copying validation files...\n",
            "Copying test files...\n",
            "Data split completed!\n"
          ]
        }
      ],
      "source": [
        "# Copy files to respective directories\n",
        "def copy_files(files, split_name):\n",
        "    for img_file in files:\n",
        "        # Copy image\n",
        "        dest_img = dataset_root / split_name / \"images\" / img_file.name\n",
        "        shutil.copy2(img_file, dest_img)\n",
        "        \n",
        "        # Copy corresponding label\n",
        "        label_file = export_labels / (img_file.stem + \".txt\")\n",
        "        if label_file.exists():\n",
        "            dest_label = dataset_root / split_name / \"labels\" / label_file.name\n",
        "            shutil.copy2(label_file, dest_label)\n",
        "\n",
        "# Copy files (this may take a few minutes)\n",
        "print(\"Copying training files...\")\n",
        "copy_files(train_files, \"train\")\n",
        "print(\"Copying validation files...\")\n",
        "copy_files(val_files, \"valid\")\n",
        "print(\"Copying test files...\")\n",
        "copy_files(test_files, \"test\")\n",
        "print(\"Data split completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Update data.yaml Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml updated!\n",
            "train: train/images\n",
            "val: valid/images\n",
            "test: test/images\n",
            "\n",
            "nc: 11\n",
            "names: ['biker', 'car', 'pedestrian', 'trafficLight', 'trafficLight-Green', 'trafficLight-GreenLeft', 'trafficLight-Red', 'trafficLight-RedLeft', 'trafficLight-Yellow', 'trafficLight-YellowLeft', 'truck']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Update data.yaml with correct paths\n",
        "# Use relative paths since YAML file is inside the dataset directory\n",
        "# YOLO interprets paths relative to the YAML file location\n",
        "yaml_content = \"\"\"train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "\n",
        "nc: 11\n",
        "names: ['biker', 'car', 'pedestrian', 'trafficLight', 'trafficLight-Green', 'trafficLight-GreenLeft', 'trafficLight-Red', 'trafficLight-RedLeft', 'trafficLight-Yellow', 'trafficLight-YellowLeft', 'truck']\n",
        "\"\"\"\n",
        "\n",
        "with open(dataset_root / \"data.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"data.yaml updated!\")\n",
        "print(yaml_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Initialize and Train YOLOv11 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available! Using GPU: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
            "CUDA Version: 11.8\n",
            "Model initialized!\n"
          ]
        }
      ],
      "source": [
        "# Check CUDA availability\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    device = 0  # Use first GPU\n",
        "else:\n",
        "    print(\"CUDA is not available. Training will use CPU (slower).\")\n",
        "    print(\"To use CUDA, make sure you have:\")\n",
        "    print(\"1. NVIDIA GPU with CUDA support\")\n",
        "    print(\"2. CUDA toolkit installed\")\n",
        "    print(\"3. PyTorch with CUDA support (install: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118)\")\n",
        "    device = 'cpu'\n",
        "\n",
        "# Initialize YOLOv11 model (you can use 'yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt')\n",
        "# 'n' = nano (fastest, smallest), 'x' = extra large (most accurate, slowest)\n",
        "model = YOLO('yolo11n.pt')  # Start with nano for faster training, change to 'yolo11s.pt' or larger for better accuracy\n",
        "\n",
        "print(\"Model initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Self Driving Car.v3-fixed-small.yolov11\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=car_detection_yolo116, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n",
            "YOLO11n summary: 181 layers, 2,591,985 parameters, 2,591,969 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 with Max-Q Design GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 4.20.6 MB/s, size: 39.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\labels.cache... 20860 images, 2446 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 20860/20860 21.3Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\images\\1478021875081281646_jpg.rf.bEZPhuyXU5hIovwQSTIp.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\images\\1478021875081281646_jpg.rf.e9552980cf8c6fef4aa02cb84c6364f5.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\images\\1478897760163798179_jpg.rf.5Pzrj3Eg3vZuyl7ztKAt.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\images\\1478897760163798179_jpg.rf.98623be50b02ff17d58f89fddf7a0c6c.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\images\\1478898145212453716_jpg.rf.6a92d7d7dd523160c990c4e4375bcea9.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\train\\images\\1478898145212453716_jpg.rf.nCaFkPk4AFMjTQAM4RTJ.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 0.70.4 MB/s, size: 32.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\valid\\labels.cache... 5960 images, 695 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 5960/5960 3.6Mit/s 0.0s0s\n",
            "Plotting labels to C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      4.29G       1.61      1.844       1.23        117        640: 100% ━━━━━━━━━━━━ 1304/1304 1.6s/it 34:16<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.568      0.289      0.271      0.132\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      3.99G      1.559      1.347      1.174        109        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 22:55<1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:240.5sss\n",
            "                   all       5960      39067      0.621      0.334      0.325      0.155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      3.97G      1.581      1.252      1.187        105        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1it/s 20:18<0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:210.4sss\n",
            "                   all       5960      39067      0.538      0.323      0.324      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      3.95G      1.586      1.167       1.19         99        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1it/s 19:35<0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:210.4sss\n",
            "                   all       5960      39067        0.7      0.344      0.362      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      3.98G      1.549      1.077      1.172        152        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 23:25<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:210.5sss\n",
            "                   all       5960      39067      0.735      0.361       0.39      0.195\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      3.99G      1.523       1.03      1.162         79        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 22:55<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:210.4sss\n",
            "                   all       5960      39067      0.755      0.377      0.424      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      3.95G      1.505      1.002      1.154        113        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0s/it 22:16<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:230.4sss\n",
            "                   all       5960      39067      0.737        0.4      0.436      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      3.96G      1.488     0.9799      1.148         91        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 23:42<0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:230.5sss\n",
            "                   all       5960      39067      0.649      0.443      0.467      0.243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      3.99G      1.479      0.958       1.14        131        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 25:20<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:250.5sss\n",
            "                   all       5960      39067       0.74      0.409      0.479      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      4.06G      1.463     0.9396      1.133        127        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 25:32<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.682       0.46      0.497       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      3.99G      1.454     0.9265      1.129        206        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:20<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067       0.63      0.473      0.516      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      3.95G      1.442     0.9112      1.123        113        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0s/it 22:07<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.741      0.478      0.525      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50         4G      1.434     0.9039      1.122        104        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:02<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.785      0.482      0.544      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      4.09G      1.425      0.889      1.113        108        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 26:15<1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.757      0.497      0.559      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      3.98G      1.417     0.8801       1.11        164        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:05<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.728      0.514      0.572      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50         4G      1.403     0.8671      1.104         55        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0s/it 22:33<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067       0.78      0.512      0.575      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      3.99G      1.404     0.8618      1.105        112        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 26:52<1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.777      0.521      0.587      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      3.94G      1.391     0.8533      1.101         92        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:44<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.752       0.53      0.598      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      4.09G      1.389     0.8447      1.098        121        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0it/s 21:42<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.789       0.53      0.616      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50         4G      1.382     0.8364      1.093         77        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 25:41<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.797      0.526       0.61      0.333\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      4.01G      1.371     0.8255       1.09         88        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:19<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.783      0.548      0.617       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      3.95G      1.367     0.8219      1.087        155        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0it/s 21:39<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067       0.79      0.551      0.628      0.346\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      3.95G      1.359     0.8137      1.083         79        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1it/s 20:08<0.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.785      0.555      0.629       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      3.94G      1.355     0.8101      1.082        131        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 23:41<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.791      0.572      0.643      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      3.99G      1.349     0.8024       1.08        107        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0it/s 21:31<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:230.4sss\n",
            "                   all       5960      39067      0.816      0.559      0.669      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      3.98G      1.345     0.7972      1.077        140        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:06<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:250.5sss\n",
            "                   all       5960      39067      0.803      0.571      0.664      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      4.01G      1.336     0.7885      1.073        160        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 26:06<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:230.4sss\n",
            "                   all       5960      39067      0.813      0.566      0.674       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      3.93G      1.335     0.7836      1.072        107        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 23:47<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:250.5sss\n",
            "                   all       5960      39067      0.821      0.579      0.676      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      3.99G      1.325      0.776      1.068        116        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 24:23<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:240.5sss\n",
            "                   all       5960      39067      0.816      0.583      0.679      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      4.08G       1.32     0.7722      1.068        100        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0s/it 22:17<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:250.5sss\n",
            "                   all       5960      39067      0.822      0.589      0.675      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      3.96G      1.312      0.764      1.065        105        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 25:02<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:260.5sss\n",
            "                   all       5960      39067      0.812      0.594      0.687      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50       4.1G      1.306     0.7594      1.062        125        640: 100% ━━━━━━━━━━━━ 1304/1304 1.7s/it 36:26<1.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.828      0.585      0.684       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      3.99G      1.304     0.7578      1.062        184        640: 100% ━━━━━━━━━━━━ 1304/1304 1.6s/it 33:56<1.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:280.5sss\n",
            "                   all       5960      39067      0.823      0.597      0.679      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      3.95G      1.293     0.7471      1.057        111        640: 100% ━━━━━━━━━━━━ 1304/1304 1.7s/it 35:53<2.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 1.7it/s 1:490.6sss\n",
            "                   all       5960      39067      0.833      0.586      0.678      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      4.07G      1.293     0.7457      1.057        111        640: 100% ━━━━━━━━━━━━ 1304/1304 1.5s/it 32:54<1.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.0it/s 1:350.5sss\n",
            "                   all       5960      39067      0.847      0.591      0.689      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      3.96G      1.281     0.7366       1.05        114        640: 100% ━━━━━━━━━━━━ 1304/1304 1.5s/it 33:09<1.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:260.5sss\n",
            "                   all       5960      39067      0.852       0.59      0.684      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      4.11G      1.282     0.7343      1.053         49        640: 100% ━━━━━━━━━━━━ 1304/1304 1.5s/it 32:43<1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:290.5sss\n",
            "                   all       5960      39067      0.851      0.599      0.701      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      4.06G      1.275     0.7257      1.048        116        640: 100% ━━━━━━━━━━━━ 1304/1304 1.4s/it 30:37<1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:240.5sss\n",
            "                   all       5960      39067      0.847      0.598        0.7      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      3.99G      1.267     0.7223      1.045        105        640: 100% ━━━━━━━━━━━━ 1304/1304 1.0s/it 22:40<1.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 1.9it/s 1:390.5sss\n",
            "                   all       5960      39067      0.847      0.602      0.705      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      3.96G      1.262     0.7168      1.045         96        640: 100% ━━━━━━━━━━━━ 1304/1304 1.6s/it 35:44<2.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 1.9it/s 1:370.5sss\n",
            "                   all       5960      39067       0.85      0.602      0.704      0.409\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      3.85G      1.267     0.6827      1.054         90        640: 100% ━━━━━━━━━━━━ 1304/1304 1.3s/it 27:13<1.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.3it/s 1:220.4sss\n",
            "                   all       5960      39067      0.845      0.604      0.707      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      3.87G      1.253     0.6728      1.049         69        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 25:24<1.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:240.5sss\n",
            "                   all       5960      39067      0.847      0.603      0.709      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      3.87G      1.242     0.6632      1.045         90        640: 100% ━━━━━━━━━━━━ 1304/1304 1.1s/it 23:14<1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:270.5sss\n",
            "                   all       5960      39067      0.848      0.605       0.71      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      3.84G      1.233     0.6543      1.042         65        640: 100% ━━━━━━━━━━━━ 1304/1304 1.7s/it 35:56<1.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:280.5sss\n",
            "                   all       5960      39067      0.845      0.609      0.713      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50       3.9G      1.221     0.6469      1.036         89        640: 100% ━━━━━━━━━━━━ 1304/1304 1.9s/it 42:02<1.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.0it/s 1:320.5sss\n",
            "                   all       5960      39067      0.842      0.613      0.714      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      3.89G      1.215     0.6425      1.035         82        640: 100% ━━━━━━━━━━━━ 1304/1304 2.5s/it 53:36<2.1ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.4it/s 1:180.4sss\n",
            "                   all       5960      39067       0.85      0.612      0.718      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      3.85G      1.204     0.6339       1.03         76        640: 100% ━━━━━━━━━━━━ 1304/1304 1.7s/it 37:47<1.6ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.0it/s 1:340.4sss\n",
            "                   all       5960      39067      0.853      0.613      0.721      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      3.84G      1.199     0.6288      1.028         70        640: 100% ━━━━━━━━━━━━ 1304/1304 1.4s/it 31:15<1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.1it/s 1:300.5sss\n",
            "                   all       5960      39067      0.858      0.613      0.723      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      3.86G       1.19     0.6227      1.026         65        640: 100% ━━━━━━━━━━━━ 1304/1304 1.2s/it 25:54<1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 1.9it/s 1:390.5sss\n",
            "                   all       5960      39067      0.856      0.614      0.725      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50       3.9G      1.183     0.6173      1.022         75        640: 100% ━━━━━━━━━━━━ 1304/1304 1.4s/it 31:11<1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:240.5sss\n",
            "                   all       5960      39067      0.855      0.614      0.725      0.427\n",
            "\n",
            "50 epochs completed in 24.040 hours.\n",
            "Optimizer stripped from C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116\\weights\\last.pt, 5.5MB\n",
            "Optimizer stripped from C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116\\weights\\best.pt, 5.5MB\n",
            "\n",
            "Validating C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116\\weights\\best.pt...\n",
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,584,297 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 2.2it/s 1:250.4sss\n",
            "                   all       5960      39067      0.855      0.614      0.724      0.427\n",
            "                 biker        494        757      0.781      0.649      0.728      0.413\n",
            "                   car       5170      25573      0.876      0.803      0.859      0.586\n",
            "            pedestrian       1421       4425      0.746      0.555      0.651      0.331\n",
            "          trafficLight        630       1043      0.849      0.802       0.85      0.532\n",
            "    trafficLight-Green        783       2128      0.813      0.645       0.73      0.351\n",
            "trafficLight-GreenLeft         80        117      0.819      0.502      0.639      0.339\n",
            "      trafficLight-Red       1062       2765      0.898      0.752      0.833      0.507\n",
            "  trafficLight-RedLeft        533        706      0.905      0.745       0.84      0.504\n",
            "   trafficLight-Yellow         57        112      0.875      0.502       0.63      0.301\n",
            "trafficLight-YellowLeft          5          5          1          0      0.351      0.221\n",
            "                 truck       1004       1436      0.843      0.802      0.854      0.611\n",
            "Speed: 0.3ms preprocess, 7.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\car_detection_yolo116\u001b[0m\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "results = model.train(\n",
        "    data=str(dataset_root / \"data.yaml\"),\n",
        "    epochs=50,  # Number of training epochs\n",
        "    imgsz=640,  # Image size\n",
        "    batch=16,   # Batch size (adjust based on your GPU memory - increase for GPU, decrease if OOM)\n",
        "    device=device,  # Use CUDA if available, otherwise CPU\n",
        "    name='car_detection_yolo11',  # Project name\n",
        "    project='runs/detect',  # Save directory\n",
        "    patience=10,  # Early stopping patience\n",
        "    save=True,\n",
        "    plots=True\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: runs\\detect\\car_detection_yolo116\\weights\\best.pt\n",
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,584,297 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2.50.8 MB/s, size: 33.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\test\\labels... 2980 images, 359 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2980/2980 213.6it/s 14.0s<0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\test\\labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 187/187 4.2it/s 45.0s0.2ss\n",
            "                   all       2980      19322      0.864      0.634      0.727      0.435\n",
            "                 biker        235        378      0.831      0.653      0.737      0.419\n",
            "                   car       2566      12756      0.874      0.802      0.861      0.591\n",
            "            pedestrian        682       2056       0.75      0.562      0.667      0.337\n",
            "          trafficLight        311        469      0.849      0.832       0.88      0.535\n",
            "    trafficLight-Green        381       1078      0.821      0.651      0.737      0.356\n",
            "trafficLight-GreenLeft         42         64      0.815      0.641      0.747      0.481\n",
            "      trafficLight-Red        511       1367      0.892      0.745      0.826      0.516\n",
            "  trafficLight-RedLeft        234        319      0.898      0.719       0.83      0.498\n",
            "   trafficLight-Yellow         20         59      0.957      0.559      0.693      0.352\n",
            "trafficLight-YellowLeft          2          2          1          0      0.166     0.0997\n",
            "                 truck        519        774      0.823      0.813      0.849      0.598\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\license-plate-recognition\\runs\\detect\\val\u001b[0m\n",
            "mAP50: 0.72656583822343\n",
            "mAP50-95: 0.43469733716343567\n"
          ]
        }
      ],
      "source": [
        "# Find the latest model automatically\n",
        "runs_dir = Path(\"runs/detect\")\n",
        "model_dirs = sorted([d for d in runs_dir.glob(\"car_detection_yolo11*\") if d.is_dir()], \n",
        "                    key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "\n",
        "if model_dirs:\n",
        "    best_model_path = model_dirs[0] / \"weights\" / \"best.pt\"\n",
        "    if best_model_path.exists():\n",
        "        print(f\"Loading model from: {best_model_path}\")\n",
        "        model = YOLO(str(best_model_path))\n",
        "        \n",
        "        # Evaluate on test set\n",
        "        metrics = model.val(data=str(dataset_root / \"data.yaml\"), split='test')\n",
        "        print(f\"mAP50: {metrics.box.map50}\")\n",
        "        print(f\"mAP50-95: {metrics.box.map}\")\n",
        "    else:\n",
        "        print(f\"Error: best.pt not found in {model_dirs[0]}\")\n",
        "        print(\"Available files:\", list((model_dirs[0] / \"weights\").glob(\"*.pt\")))\n",
        "else:\n",
        "    print(\"Error: No model directories found. Please train the model first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Test Detection on Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 c:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\test\\images\\1478019956186247611_jpg.rf.9ad113e7eb74453890500935ec00590a.jpg: 640x640 2 cars, 2 trucks, 93.4ms\n",
            "Speed: 6.2ms preprocess, 93.4ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detections in 1478019956186247611_jpg.rf.9ad113e7eb74453890500935ec00590a.jpg:\n",
            "  - car: 0.74\n",
            "  - car: 0.57\n",
            "  - truck: 0.44\n",
            "  - truck: 0.39\n",
            "\n",
            "image 1/1 c:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\test\\images\\1478019957180061202_jpg.rf.YHpll4d5Wk2IKGKflOe3.jpg: 640x640 4 cars, 1 truck, 13.6ms\n",
            "Speed: 3.2ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detections in 1478019957180061202_jpg.rf.YHpll4d5Wk2IKGKflOe3.jpg:\n",
            "  - car: 0.84\n",
            "  - truck: 0.78\n",
            "  - car: 0.72\n",
            "  - car: 0.60\n",
            "  - car: 0.29\n",
            "\n",
            "image 1/1 c:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\Self Driving Car.v3-fixed-small.yolov11\\test\\images\\1478019962181150666_jpg.rf.230d158a17ea339ca53495e948e85bc7.jpg: 640x640 5 cars, 1 pedestrian, 17.2ms\n",
            "Speed: 4.8ms preprocess, 17.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detections in 1478019962181150666_jpg.rf.230d158a17ea339ca53495e948e85bc7.jpg:\n",
            "  - car: 0.89\n",
            "  - car: 0.75\n",
            "  - car: 0.61\n",
            "  - pedestrian: 0.37\n",
            "  - car: 0.32\n",
            "  - car: 0.31\n"
          ]
        }
      ],
      "source": [
        "# Test on a few sample images\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a few test images\n",
        "test_images = list((dataset_root / \"test\" / \"images\").glob(\"*.jpg\"))[:3]\n",
        "\n",
        "for img_path in test_images:\n",
        "    # Run inference\n",
        "    results = model(str(img_path))\n",
        "    \n",
        "    # Plot results\n",
        "    for r in results:\n",
        "        im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "        im_rgb = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(im_rgb)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Detection: {img_path.name}\")\n",
        "        plt.show()\n",
        "        \n",
        "        # Print detection info\n",
        "        print(f\"\\nDetections in {img_path.name}:\")\n",
        "        for box in r.boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            class_name = model.names[cls]\n",
        "            print(f\"  - {class_name}: {conf:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export Model for Streamlit App\n",
        "\n",
        "The best model will be saved at: `runs/detect/car_detection_yolo11/weights/best.pt`\n",
        "\n",
        "Copy this file to the root directory for use in the Streamlit app.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model copied from runs\\detect\\car_detection_yolo116\\weights\\best.pt to car_detection_model.pt\n"
          ]
        }
      ],
      "source": [
        "# Copy the best model to root directory for easy access\n",
        "import shutil\n",
        "\n",
        "# Find the latest model automatically\n",
        "runs_dir = Path(\"runs/detect\")\n",
        "model_dirs = sorted([d for d in runs_dir.glob(\"car_detection_yolo11*\") if d.is_dir()], \n",
        "                    key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "\n",
        "if model_dirs:\n",
        "    best_model = model_dirs[0] / \"weights\" / \"best.pt\"\n",
        "    if best_model.exists():\n",
        "        shutil.copy2(best_model, \"car_detection_model.pt\")\n",
        "        print(f\"Model copied from {best_model} to car_detection_model.pt\")\n",
        "    else:\n",
        "        print(f\"Error: best.pt not found in {model_dirs[0]}\")\n",
        "        print(\"Available files:\", list((model_dirs[0] / \"weights\").glob(\"*.pt\")))\n",
        "else:\n",
        "    print(\"Error: No model directories found. Please train the model first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
