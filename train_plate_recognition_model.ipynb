{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# License Plate Detection Model Training with YOLOv11\n",
        "\n",
        "This notebook trains a YOLOv11 model to detect license plates in images using the plateRecignation dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install ultralytics pillow opencv-python -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (2.7.1+cu118)\n",
            "Requirement already satisfied: torchvision in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (0.22.1+cu118)\n",
            "Requirement already satisfied: filelock in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (2025.10.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\barky\\documents\\i3\\s1\\computer vision\\projet\\cardetection\\venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "Train images: 567\n",
            "Test images: 142\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "import random\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Define paths\n",
        "dataset_root = Path(\"plateRecignation\")\n",
        "train_dir = dataset_root / \"train\"\n",
        "test_dir = dataset_root / \"test\"\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"Train images: {len(list(train_dir.glob('*.jpg')))}\")\n",
        "print(f\"Test images: {len(list(test_dir.glob('*.jpg')))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Convert Pascal VOC XML to YOLO Format\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversion function defined!\n"
          ]
        }
      ],
      "source": [
        "def convert_xml_to_yolo(xml_path, output_dir):\n",
        "    \"\"\"\n",
        "    Convert Pascal VOC XML annotation to YOLO format.\n",
        "    YOLO format: class_id center_x center_y width height (normalized 0-1)\n",
        "    \"\"\"\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    # Get image dimensions\n",
        "    size = root.find('size')\n",
        "    img_width = int(size.find('width').text)\n",
        "    img_height = int(size.find('height').text)\n",
        "    \n",
        "    # Create output label file\n",
        "    label_file = output_dir / (xml_path.stem + '.txt')\n",
        "    \n",
        "    with open(label_file, 'w') as f:\n",
        "        # Find all objects (license plates)\n",
        "        for obj in root.findall('object'):\n",
        "            # Class name is 'LP' (License Plate)\n",
        "            class_name = obj.find('name').text\n",
        "            \n",
        "            # For YOLO, we use class_id 0 for license plate (single class)\n",
        "            class_id = 0\n",
        "            \n",
        "            # Get bounding box coordinates\n",
        "            bndbox = obj.find('bndbox')\n",
        "            xmin = int(bndbox.find('xmin').text)\n",
        "            ymin = int(bndbox.find('ymin').text)\n",
        "            xmax = int(bndbox.find('xmax').text)\n",
        "            ymax = int(bndbox.find('ymax').text)\n",
        "            \n",
        "            # Convert to YOLO format (normalized center coordinates and dimensions)\n",
        "            center_x = (xmin + xmax) / 2.0 / img_width\n",
        "            center_y = (ymin + ymax) / 2.0 / img_height\n",
        "            width = (xmax - xmin) / img_width\n",
        "            height = (ymax - ymin) / img_height\n",
        "            \n",
        "            # Write to file\n",
        "            f.write(f\"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "    \n",
        "    return label_file.exists()\n",
        "\n",
        "print(\"Conversion function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO dataset directories created!\n"
          ]
        }
      ],
      "source": [
        "# Create YOLO dataset structure\n",
        "yolo_dataset = Path(\"plateRecignation_yolo\")\n",
        "for split in [\"train\", \"valid\"]:\n",
        "    (yolo_dataset / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "    (yolo_dataset / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"YOLO dataset directories created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training images: 567\n",
            "Train split: 453, Validation split: 114\n"
          ]
        }
      ],
      "source": [
        "# Get all training images\n",
        "train_images = list(train_dir.glob(\"*.jpg\"))\n",
        "print(f\"Total training images: {len(train_images)}\")\n",
        "\n",
        "# Shuffle and split: 80% train, 20% validation\n",
        "random.shuffle(train_images)\n",
        "split_idx = int(0.8 * len(train_images))\n",
        "train_split = train_images[:split_idx]\n",
        "val_split = train_images[split_idx:]\n",
        "\n",
        "print(f\"Train split: {len(train_split)}, Validation split: {len(val_split)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing training images...\n",
            "Processed 453 training images\n"
          ]
        }
      ],
      "source": [
        "# Process training images\n",
        "print(\"Processing training images...\")\n",
        "for img_path in train_split:\n",
        "    # Copy image\n",
        "    dest_img = yolo_dataset / \"train\" / \"images\" / img_path.name\n",
        "    shutil.copy2(img_path, dest_img)\n",
        "    \n",
        "    # Convert and save label\n",
        "    xml_path = train_dir / (img_path.stem + \".xml\")\n",
        "    if xml_path.exists():\n",
        "        convert_xml_to_yolo(xml_path, yolo_dataset / \"train\" / \"labels\")\n",
        "    else:\n",
        "        print(f\"Warning: XML not found for {img_path.name}\")\n",
        "\n",
        "print(f\"Processed {len(train_split)} training images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing validation images...\n",
            "Processed 114 validation images\n"
          ]
        }
      ],
      "source": [
        "# Process validation images\n",
        "print(\"Processing validation images...\")\n",
        "for img_path in val_split:\n",
        "    # Copy image\n",
        "    dest_img = yolo_dataset / \"valid\" / \"images\" / img_path.name\n",
        "    shutil.copy2(img_path, dest_img)\n",
        "    \n",
        "    # Convert and save label\n",
        "    xml_path = train_dir / (img_path.stem + \".xml\")\n",
        "    if xml_path.exists():\n",
        "        convert_xml_to_yolo(xml_path, yolo_dataset / \"valid\" / \"labels\")\n",
        "    else:\n",
        "        print(f\"Warning: XML not found for {img_path.name}\")\n",
        "\n",
        "print(f\"Processed {len(val_split)} validation images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create data.yaml Configuration File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml created!\n",
            "train: train/images\n",
            "val: valid/images\n",
            "\n",
            "nc: 1\n",
            "names: ['license_plate']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create data.yaml file for YOLO\n",
        "yaml_content = \"\"\"train: train/images\n",
        "val: valid/images\n",
        "\n",
        "nc: 1\n",
        "names: ['license_plate']\n",
        "\"\"\"\n",
        "\n",
        "yaml_path = yolo_dataset / \"data.yaml\"\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"data.yaml created!\")\n",
        "print(yaml_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize and Train YOLOv11 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available! Using GPU: NVIDIA GeForce GTX 1650 with Max-Q Design\n",
            "CUDA Version: 11.8\n",
            "Model initialized!\n"
          ]
        }
      ],
      "source": [
        "# Check CUDA availability\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    device = 0  # Use first GPU\n",
        "else:\n",
        "    print(\"CUDA is not available. Training will use CPU (slower).\")\n",
        "    device = 'cpu'\n",
        "\n",
        "# Initialize YOLOv11 model\n",
        "# Options: 'yolo11n.pt' (nano - fastest), 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt' (most accurate)\n",
        "model = YOLO('yolo11n.pt')  # Start with nano for faster training\n",
        "\n",
        "print(\"Model initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.234 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=plateRecignation_yolo\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=plate_detection_yolo11, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "WARNING \u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 with Max-Q Design GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 14.715.1 MB/s, size: 143.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\train\\labels... 453 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 453/453 205.1it/s 2.2s0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 7.06.2 MB/s, size: 213.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\valid\\labels... 114 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 114/114 92.7it/s 1.2s0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\valid\\labels.cache\n",
            "Plotting labels to C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      4.03G      1.293       2.96      1.168         10        640: 100% ━━━━━━━━━━━━ 29/29 4.1s/it 1:591.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.9it/s 2.1s0.9s\n",
            "                   all        114        114    0.00333          1      0.708      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      3.85G      1.213      1.907      1.084          9        640: 100% ━━━━━━━━━━━━ 29/29 3.0s/it 1:272.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.1it/s 1.9s0.8s\n",
            "                   all        114        114    0.00333          1      0.121     0.0728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      3.87G      1.225      1.627      1.109          6        640: 100% ━━━━━━━━━━━━ 29/29 2.7s/it 1:191.6sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.974      0.661      0.922      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      4.06G       1.18      1.437       1.09          9        640: 100% ━━━━━━━━━━━━ 29/29 3.3s/it 1:351.3sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.7s\n",
            "                   all        114        114      0.925      0.842      0.914      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      3.85G      1.133      1.264      1.048          4        640: 100% ━━━━━━━━━━━━ 29/29 2.4s/it 1:101.3sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.6s0.7s\n",
            "                   all        114        114      0.867      0.802      0.889      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      3.87G      1.138       1.13      1.056         12        640: 100% ━━━━━━━━━━━━ 29/29 2.4s/it 1:111.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s0.7s\n",
            "                   all        114        114      0.884      0.904      0.959      0.641\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      4.06G      1.085      1.044      1.018         13        640: 100% ━━━━━━━━━━━━ 29/29 3.4s/it 1:381.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.962      0.965      0.986      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      4.06G      1.062     0.9494      1.027          6        640: 100% ━━━━━━━━━━━━ 29/29 3.1s/it 1:291.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114       0.89      0.904      0.962      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      3.85G       1.06     0.9076      1.024         13        640: 100% ━━━━━━━━━━━━ 29/29 2.2s/it 1:051.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.7s0.7s\n",
            "                   all        114        114      0.982      0.949      0.986      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      3.87G      1.046      0.829       1.01         12        640: 100% ━━━━━━━━━━━━ 29/29 2.2s/it 1:041.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s0.7s\n",
            "                   all        114        114      0.956       0.96      0.977      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      4.06G      1.106     0.8322      1.034          8        640: 100% ━━━━━━━━━━━━ 29/29 3.1s/it 1:311.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.986      0.912      0.968      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      4.06G      1.081     0.8218      1.046          7        640: 100% ━━━━━━━━━━━━ 29/29 3.2s/it 1:321.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114      0.955       0.94      0.975      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      3.85G     0.9907     0.7385     0.9893         12        640: 100% ━━━━━━━━━━━━ 29/29 2.3s/it 1:071.5s8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114      0.974      0.994      0.994      0.721\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      3.87G     0.9936      0.716     0.9927         11        640: 100% ━━━━━━━━━━━━ 29/29 2.4s/it 1:091.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.974      0.981      0.992      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      4.06G     0.9944     0.7092     0.9882          7        640: 100% ━━━━━━━━━━━━ 29/29 3.2s/it 1:321.1sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.973      0.991      0.992      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      4.06G     0.9776     0.6899     0.9862          5        640: 100% ━━━━━━━━━━━━ 29/29 3.1s/it 1:301.3sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s0.7s\n",
            "                   all        114        114      0.983      0.992      0.995      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      3.85G     0.9641     0.6802      0.989         10        640: 100% ━━━━━━━━━━━━ 29/29 2.4s/it 1:081.5sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.982      0.982      0.992      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      3.87G     0.9681     0.6643     0.9941          9        640: 100% ━━━━━━━━━━━━ 29/29 2.3s/it 1:071.4s6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114      0.963      0.991      0.989       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      4.06G     0.9843     0.6476     0.9753         15        640: 100% ━━━━━━━━━━━━ 29/29 3.2s/it 1:321.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s0.7s\n",
            "                   all        114        114      0.957      0.969      0.985      0.718\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      4.06G     0.9409     0.6327     0.9769         12        640: 100% ━━━━━━━━━━━━ 29/29 3.2s/it 1:321.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114      0.972      0.982      0.993      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      3.85G     0.9161     0.6093     0.9807          8        640: 100% ━━━━━━━━━━━━ 29/29 2.3s/it 1:081.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114          1       0.99      0.995      0.732\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      4.06G     0.9377     0.6219     0.9686          9        640: 100% ━━━━━━━━━━━━ 29/29 3.1s/it 1:301.3sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114      0.983      0.982      0.995       0.73\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      4.06G     0.9188     0.6001     0.9641          5        640: 100% ━━━━━━━━━━━━ 29/29 3.2s/it 1:341.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.7s\n",
            "                   all        114        114      0.999      0.991      0.995      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      4.06G     0.9582     0.6036     0.9573         12        640: 100% ━━━━━━━━━━━━ 29/29 3.2s/it 1:341.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114       0.97      0.991      0.994      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      3.85G     0.9367     0.5924     0.9698          9        640: 100% ━━━━━━━━━━━━ 29/29 2.4s/it 1:081.4sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.983      0.991      0.992        0.7\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      3.87G     0.9107     0.5871     0.9711         10        640: 100% ━━━━━━━━━━━━ 29/29 2.3s/it 1:061.4s4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.985          1      0.993      0.729\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      4.06G      0.876     0.5624     0.9546         11        640: 100% ━━━━━━━━━━━━ 29/29 3.3s/it 1:341.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.993          1      0.995      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      4.06G     0.8694     0.5439     0.9424         11        640: 100% ━━━━━━━━━━━━ 29/29 3.1s/it 1:311.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.985      0.991      0.994      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      3.85G     0.9013     0.5597     0.9566         13        640: 100% ━━━━━━━━━━━━ 29/29 2.1s/it 1:001.2sss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.3s0.5s\n",
            "                   all        114        114      0.995      0.974      0.995      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      3.87G     0.8998     0.5506     0.9493         14        640: 100% ━━━━━━━━━━━━ 29/29 2.0s/it 58.1s1.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.3s0.5s\n",
            "                   all        114        114          1      0.972      0.994      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      4.06G     0.8819      0.544     0.9532          8        640: 100% ━━━━━━━━━━━━ 29/29 1.5s/it 42.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.985      0.991      0.995      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      4.06G     0.8533      0.542     0.9392          7        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 40.7s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.998          1      0.995      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      3.85G     0.8242     0.5373      0.924          8        640: 100% ━━━━━━━━━━━━ 29/29 1.5s/it 44.0s1.1ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.998          1      0.995       0.75\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      4.06G     0.8299     0.5283     0.9266          4        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 41.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114          1          1      0.995      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      4.06G     0.8399     0.5206     0.9339          5        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 40.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.983      0.999      0.995      0.759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      4.06G     0.8388     0.5212     0.9323         11        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 39.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.998      0.982      0.995      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      3.85G     0.8358     0.5005     0.9268         14        640: 100% ━━━━━━━━━━━━ 29/29 1.6s/it 45.5s1.1ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.993      0.982      0.995      0.772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      4.06G     0.8383     0.5172     0.9317         16        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 40.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.998      0.991      0.995      0.773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      4.06G     0.8131     0.4982     0.9299          7        640: 100% ━━━━━━━━━━━━ 29/29 1.0it/s 28.8s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.3s0.6s\n",
            "                   all        114        114      0.997      0.982      0.995      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      4.06G      0.836     0.5058     0.9201         13        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 31.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.3s0.6s\n",
            "                   all        114        114      0.998      0.991      0.995      0.749\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      3.85G     0.8131     0.4817     0.9247         11        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 32.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.996      0.991      0.995      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      4.06G     0.8122     0.4943     0.9268         10        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 32.2s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.3s0.5s\n",
            "                   all        114        114       0.99      0.991      0.995      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100      4.06G      0.811     0.4915     0.9248         12        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 30.5s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.3s0.5s\n",
            "                   all        114        114          1       0.99      0.995      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100      4.06G     0.8114     0.4878     0.9298         11        640: 100% ━━━━━━━━━━━━ 29/29 1.1it/s 27.0s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.982      0.991      0.993      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      3.85G     0.7944     0.4724     0.9242          5        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 31.8s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.998      0.991      0.995      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      3.87G     0.7981     0.4718     0.9156         13        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 33.5s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.2s0.5s\n",
            "                   all        114        114      0.991       0.99      0.995      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100      4.06G     0.8123     0.4753     0.9281          8        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 31.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.3s0.6s\n",
            "                   all        114        114      0.989      0.982      0.994      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      4.06G     0.8039     0.4766     0.9163          8        640: 100% ━━━━━━━━━━━━ 29/29 1.0s/it 29.2s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114       0.99      0.991      0.994      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100      3.85G     0.7868     0.4716     0.9071         10        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 35.6s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s0.6s\n",
            "                   all        114        114      0.991          1      0.995      0.762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100      3.87G     0.7699     0.4599     0.9154          8        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.8s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.6s\n",
            "                   all        114        114      0.998      0.991      0.995      0.775\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      4.06G     0.8107     0.4713      0.918          8        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.5s0.6s\n",
            "                   all        114        114      0.995      0.991      0.995      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100      4.06G     0.8054     0.4758      0.931          9        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 33.1s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.985      0.991      0.995      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100      3.85G     0.7338     0.4379     0.9015          4        640: 100% ━━━━━━━━━━━━ 29/29 1.3s/it 37.9s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.998      0.991      0.995      0.768\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100      4.06G     0.7367     0.4512     0.8944          9        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.8s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.999          1      0.995      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      4.06G     0.7514     0.4426     0.9077          9        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.2s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.7s\n",
            "                   all        114        114      0.991          1      0.995      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      4.06G     0.7381     0.4477     0.8979         10        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.5s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.998      0.991      0.995      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      3.85G     0.7165      0.441     0.8924          5        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.4s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114          1      0.999      0.995       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      4.06G       0.72     0.4286     0.8833          8        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 35.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.6s\n",
            "                   all        114        114       0.99          1      0.995      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      4.06G     0.7295     0.4397     0.8987         11        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.4s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.7s\n",
            "                   all        114        114      0.991      0.982      0.995      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      4.06G     0.7304     0.4373     0.8995         11        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 33.0s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114       0.99          1      0.995      0.781\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      3.85G     0.7096      0.421      0.896          6        640: 100% ━━━━━━━━━━━━ 29/29 1.5s/it 44.3s1.1ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114      0.991          1      0.995      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      4.06G     0.7243     0.4333     0.8935          7        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 41.3s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s0.6s\n",
            "                   all        114        114      0.991      0.999      0.995      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      4.06G     0.7232     0.4308     0.8931          7        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 35.6s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s0.6s\n",
            "                   all        114        114      0.987      0.991      0.995      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100      4.06G     0.7319     0.4249     0.8905         11        640: 100% ━━━━━━━━━━━━ 29/29 1.3s/it 36.8s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.981          1      0.995       0.78\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      3.85G     0.7313     0.4325     0.8998          9        640: 100% ━━━━━━━━━━━━ 29/29 1.5s/it 43.4s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s0.6s\n",
            "                   all        114        114       0.99      0.991      0.995      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      4.06G     0.7093      0.425     0.8981          7        640: 100% ━━━━━━━━━━━━ 29/29 1.5s/it 43.6s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s0.7s\n",
            "                   all        114        114      0.989      0.991      0.992      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      4.06G     0.6822       0.42      0.886         12        640: 100% ━━━━━━━━━━━━ 29/29 1.5s/it 42.6s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s0.6s\n",
            "                   all        114        114      0.988      0.991      0.993      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      4.06G      0.691     0.4159     0.8871          8        640: 100% ━━━━━━━━━━━━ 29/29 1.3s/it 36.6s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.4s0.6s\n",
            "                   all        114        114      0.999      0.991      0.995       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      3.85G     0.6982     0.4197     0.8935          8        640: 100% ━━━━━━━━━━━━ 29/29 1.6s/it 45.2s1.2ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s0.6s\n",
            "                   all        114        114          1          1      0.995      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100      4.06G     0.6803     0.4105     0.8987         16        640: 100% ━━━━━━━━━━━━ 29/29 1.6s/it 47.6s1.4ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s0.7s\n",
            "                   all        114        114       0.99          1      0.995      0.803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      4.06G     0.6765     0.4074     0.8831         14        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 31.7s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s0.6s\n",
            "                   all        114        114      0.999      0.991      0.995      0.796\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      4.06G      0.673     0.3965     0.8856          9        640: 100% ━━━━━━━━━━━━ 29/29 1.2s/it 34.9s0.8ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s0.6s\n",
            "                   all        114        114      0.979          1      0.994      0.794\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      3.85G     0.6837     0.4005     0.8857         15        640: 100% ━━━━━━━━━━━━ 29/29 1.9s/it 55.9s1.4ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.8s0.7s\n",
            "                   all        114        114      0.989          1      0.993      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      4.06G     0.6915     0.4075     0.8891         11        640: 100% ━━━━━━━━━━━━ 29/29 1.4s/it 41.2s0.9ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.4s0.6s\n",
            "                   all        114        114      0.983          1      0.993      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100      4.06G     0.6834     0.4018     0.8769         11        640: 100% ━━━━━━━━━━━━ 29/29 1.3s/it 37.9s1.0ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.6s0.7s\n",
            "                   all        114        114       0.99          1      0.989      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100      4.06G     0.6597     0.3884     0.8831         10        640: 100% ━━━━━━━━━━━━ 29/29 1.1s/it 30.6s0.7ss\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s0.6s\n",
            "                   all        114        114      0.991      0.998      0.994      0.788\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 15 epochs. Best results observed at epoch 61, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=15) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "76 epochs completed in 1.202 hours.\n",
            "Optimizer stripped from C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11\\weights\\last.pt, 5.5MB\n",
            "Optimizer stripped from C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11\\weights\\best.pt, 5.5MB\n",
            "\n",
            "Validating C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11\\weights\\best.pt...\n",
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.7it/s 2.3s0.9s\n",
            "                   all        114        114      0.991          1      0.995      0.805\n",
            "Speed: 0.4ms preprocess, 8.1ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\runs\\detect\\plate_detection_yolo11\u001b[0m\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "results = model.train(\n",
        "    data=str(yaml_path),\n",
        "    epochs=100,  # Number of training epochs\n",
        "    imgsz=640,  # Image size\n",
        "    batch=16,   # Batch size (adjust based on your GPU memory)\n",
        "    device=device,  # Use CUDA if available, otherwise CPU\n",
        "    name='plate_detection_yolo11',  # Project name\n",
        "    project='runs/detect',  # Save directory\n",
        "    patience=15,  # Early stopping patience\n",
        "    save=True,\n",
        "    plots=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: runs\\detect\\plate_detection_yolo11\\weights\\best.pt\n",
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 369.696.4 MB/s, size: 211.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\valid\\labels.cache... 114 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 114/114 157.0Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 8/8 1.4s/it 11.2s0.3s\n",
            "                   all        114        114      0.991          1      0.995      0.804\n",
            "Speed: 3.6ms preprocess, 9.8ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\license-plate-recognition\\runs\\detect\\val2\u001b[0m\n",
            "\n",
            "Validation Results:\n",
            "mAP50: 0.9950\n",
            "mAP50-95: 0.8044\n",
            "Precision: 0.9913\n",
            "Recall: 0.9997\n"
          ]
        }
      ],
      "source": [
        "# Find the latest model automatically\n",
        "runs_dir = Path(\"runs/detect\")\n",
        "model_dirs = sorted([d for d in runs_dir.glob(\"plate_detection_yolo11*\") if d.is_dir()], \n",
        "                    key=lambda x: x.stat().st_mtime, reverse=True)\n",
        "\n",
        "if model_dirs:\n",
        "    best_model_path = model_dirs[0] / \"weights\" / \"best.pt\"\n",
        "    if best_model_path.exists():\n",
        "        print(f\"Loading model from: {best_model_path}\")\n",
        "        model = YOLO(str(best_model_path))\n",
        "        \n",
        "        # Evaluate on validation set\n",
        "        metrics = model.val(data=str(yaml_path), split='val')\n",
        "        print(f\"\\nValidation Results:\")\n",
        "        print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "        print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "        print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "        print(f\"Recall: {metrics.box.mr:.4f}\")\n",
        "    else:\n",
        "        print(f\"Error: best.pt not found in {model_dirs[0]}\")\n",
        "        print(\"Available files:\", list((model_dirs[0] / \"weights\").glob(\"*.pt\")))\n",
        "else:\n",
        "    print(\"Error: No model directories found. Please train the model first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test Detection on Sample Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 c:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\valid\\images\\148.jpg: 480x640 1 license_plate, 84.7ms\n",
            "Speed: 4.5ms preprocess, 84.7ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 c:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\valid\\images\\158.jpg: 480x640 1 license_plate, 20.2ms\n",
            "Speed: 4.4ms preprocess, 20.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 c:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\valid\\images\\167.jpg: 640x480 1 license_plate, 69.1ms\n",
            "Speed: 4.0ms preprocess, 69.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample predictions displayed!\n"
          ]
        }
      ],
      "source": [
        "# Test on a few sample images from validation set\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get a few validation images\n",
        "val_images = list((yolo_dataset / \"valid\" / \"images\").glob(\"*.jpg\"))[:3]\n",
        "\n",
        "fig, axes = plt.subplots(1, len(val_images), figsize=(15, 5))\n",
        "if len(val_images) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, img_path in enumerate(val_images):\n",
        "    # Run inference\n",
        "    results = model(str(img_path))\n",
        "    \n",
        "    # Plot results\n",
        "    annotated_img = results[0].plot()\n",
        "    axes[idx].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
        "    axes[idx].axis('off')\n",
        "    axes[idx].set_title(f\"Image: {img_path.name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Sample predictions displayed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test on Test Set Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total test images: 142\n",
            "Processing test images...\n",
            "Processed 142 test images\n"
          ]
        }
      ],
      "source": [
        "# Process test images for evaluation\n",
        "test_images = list(test_dir.glob(\"*.jpg\"))\n",
        "print(f\"Total test images: {len(test_images)}\")\n",
        "\n",
        "# Create test directory structure\n",
        "(yolo_dataset / \"test\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
        "(yolo_dataset / \"test\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Process test images\n",
        "print(\"Processing test images...\")\n",
        "for img_path in test_images:\n",
        "    # Copy image\n",
        "    dest_img = yolo_dataset / \"test\" / \"images\" / img_path.name\n",
        "    shutil.copy2(img_path, dest_img)\n",
        "    \n",
        "    # Convert and save label\n",
        "    xml_path = test_dir / (img_path.stem + \".xml\")\n",
        "    if xml_path.exists():\n",
        "        convert_xml_to_yolo(xml_path, yolo_dataset / \"test\" / \"labels\")\n",
        "\n",
        "print(f\"Processed {len(test_images)} test images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml updated with test set!\n"
          ]
        }
      ],
      "source": [
        "# Update data.yaml to include test set\n",
        "yaml_content = \"\"\"train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['license_plate']\n",
        "\"\"\"\n",
        "\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"data.yaml updated with test set!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.233  Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1650 with Max-Q Design, 4096MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 11.36.7 MB/s, size: 124.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\test\\labels... 142 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 142/142 245.9it/s 0.6s0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\CarDetection\\plateRecignation_yolo\\test\\labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 9/9 2.9it/s 3.1s0.3ss\n",
            "                   all        142        142      0.993          1      0.995      0.765\n",
            "Speed: 2.6ms preprocess, 6.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\Barky\\Documents\\I3\\S1\\Computer Vision\\Projet\\license-plate-recognition\\runs\\detect\\val3\u001b[0m\n",
            "\n",
            "Test Set Results:\n",
            "mAP50: 0.9949\n",
            "mAP50-95: 0.7651\n",
            "Precision: 0.9930\n",
            "Recall: 0.9997\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on test set\n",
        "if model_dirs and (model_dirs[0] / \"weights\" / \"best.pt\").exists():\n",
        "    model = YOLO(str(model_dirs[0] / \"weights\" / \"best.pt\"))\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    test_metrics = model.val(data=str(yaml_path), split='test')\n",
        "    print(f\"\\nTest Set Results:\")\n",
        "    print(f\"mAP50: {test_metrics.box.map50:.4f}\")\n",
        "    print(f\"mAP50-95: {test_metrics.box.map:.4f}\")\n",
        "    print(f\"Precision: {test_metrics.box.mp:.4f}\")\n",
        "    print(f\"Recall: {test_metrics.box.mr:.4f}\")\n",
        "else:\n",
        "    print(\"Model not found. Please train the model first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Model for Inference\n",
        "\n",
        "The trained model is saved at:\n",
        "- **Best model**: `runs/detect/plate_detection_yolo11*/weights/best.pt`\n",
        "- **Last model**: `runs/detect/plate_detection_yolo11*/weights/last.pt`\n",
        "\n",
        "You can use the model for inference like this:\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO('runs/detect/plate_detection_yolo11*/weights/best.pt')\n",
        "\n",
        "# Run inference on an image\n",
        "results = model('path/to/image.jpg')\n",
        "\n",
        "# Display results\n",
        "results[0].show()\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
